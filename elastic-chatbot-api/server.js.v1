require("dotenv").config();
const express = require("express");
const cors = require("cors");
const { Client } = require("@elastic/elasticsearch");
const axios = require("axios");

const app = express();
const PORT = 3000;

app.use(cors());
app.use(express.json());

const esClient = new Client({ node: "http://localhost:9200" });

// Route to handle chatbot requests
app.post("/chat", async (req, res) => {
  const userMessage = req.body.message;

  // Search Elasticsearch for a relevant answer
  const { hits } = await esClient.search({
    index: "chatbot",
    query: { match: { question: userMessage } },
  });

  if (hits.hits.length > 0) {
    return res.json({ response: hits.hits[0]._source.answer });
  }

  // If no answer is found, fallback to OpenAI API
  try {
    const openAIResponse = await axios.post(
      "https://api.openai.com/v1/completions",
      {
        model: "gpt-3.5-turbo",
        messages: [{ role: "user", content: userMessage }],
      },
      { headers: { Authorization: `Bearer ${process.env.OPENAI_API_KEY}` } }
    );

    return res.json({ response: openAIResponse.data.choices[0].message.content });
  } catch (error) {
    return res.status(500).json({ response: "Error fetching response" });
  }
});

// Start the backend server
app.listen(PORT, () => console.log(`Backend running on http://localhost:${PORT}`));